{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wgan_cifar10_tf2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPnekF62ByZDmsUx/ftDeW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalnishar/dcgan_cifar10/blob/master/wgan_cifar10_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYOC7XyQloQ7",
        "colab_type": "text"
      },
      "source": [
        "This notebook implements a deep convolutional generative adversarial network (DCGAN) to generate CIFAR-10 images from noise vector sampled from normal distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkFLn5mPhEot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Copyright 2020 Harshal Nishar\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Dye1S2991w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "%load_ext tensorboard\n",
        "\n",
        "!rm -rf generated_images_*.png\n",
        "!rm -rf logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI1h1A9Nkat0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import urllib\n",
        "import zipfile \n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "# from tensorflow.contrib.training import HParams\n",
        "from IPython.display import Image\n",
        "\n",
        "class HParams:\n",
        "    n_classes = 10  # number of different classes in dataset\n",
        "    batch_size = 32  # training batch size\n",
        "    latent_size = 128\n",
        "    dis_learning_rate = 0.0001\n",
        "    gen_learning_rate = 0.0001\n",
        "    n_critic = 2\n",
        "    n_epochs = 100  # number of epochs to train\n",
        "    data_dir = '/tmp/cifar-data/'  # path to data directory\n",
        "    checkpoint_dir = '/tmp/checkpoints/'  # path to model checkpoint directory\n",
        "\n",
        "hparams = HParams()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Gqw7aZ4KLO",
        "colab_type": "text"
      },
      "source": [
        "Functions for Reading CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EpQ-iJN94G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Below code for reading CIFAR-10 dataset is taken from: https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/cifar10.py\n",
        "# URL for the data-set on the internet.\n",
        "data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "\n",
        "# Width and height of each image.\n",
        "img_size = 32\n",
        "\n",
        "# Number of channels in each image, 3 channels: Red, Green, Blue.\n",
        "num_channels = 3\n",
        "\n",
        "# Length of an image when flattened to a 1-dim array.\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "\n",
        "# Number of classes.\n",
        "num_classes = hparams.n_classes\n",
        "\n",
        "########################################################################\n",
        "# Various constants used to allocate arrays of the correct size.\n",
        "\n",
        "# Number of files for the training-set.\n",
        "_num_files_train = 5\n",
        "\n",
        "# Number of images for each batch-file in the training-set.\n",
        "_images_per_file = 10000\n",
        "\n",
        "# Total number of images in the training-set.\n",
        "# This is used to pre-allocate arrays for efficiency.\n",
        "_num_images_train = _num_files_train * _images_per_file\n",
        "\n",
        "########################################################################\n",
        "# Private functions for downloading, unpacking and loading data-files.\n",
        "\n",
        "\n",
        "def download(base_url, filename, download_dir):\n",
        "    \"\"\"\n",
        "    Download the given file if it does not already exist in the download_dir.\n",
        "    :param base_url: The internet URL without the filename.\n",
        "    :param filename: The filename that will be added to the base_url.\n",
        "    :param download_dir: Local directory for storing the file.\n",
        "    :return: Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Path for local file.\n",
        "    save_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists, otherwise we need to download it now.\n",
        "    if not os.path.exists(save_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        print(\"Downloading\", filename, \"...\")\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        url = base_url + filename\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=save_path)\n",
        "\n",
        "        print(\" Done!\")\n",
        "\n",
        "\n",
        "def maybe_download_and_extract(url=data_url, download_dir=hparams.data_dir):\n",
        "    \"\"\"\n",
        "    Download and extract the data if it doesn't already exist.\n",
        "    Assumes the url is a tar-ball file.\n",
        "    :param url:\n",
        "        Internet URL for the tar-file to download.\n",
        "        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    :param download_dir:\n",
        "        Directory where the downloaded file is saved.\n",
        "        Example: \"data/CIFAR-10/\"\n",
        "    :return:\n",
        "        Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filename for saving the file downloaded from the internet.\n",
        "    # Use the filename from the URL and add it to the download_dir.\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    # Check if the file already exists.\n",
        "    # If it exists then we assume it has also been extracted,\n",
        "    # otherwise we need to download and extract it now.\n",
        "    if not os.path.exists(file_path):\n",
        "        # Check if the download directory exists, otherwise create it.\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        # Download the file from the internet.\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=file_path)\n",
        "\n",
        "        print()\n",
        "        print(\"Download finished. Extracting files.\")\n",
        "\n",
        "        if file_path.endswith(\".zip\"):\n",
        "            # Unpack the zip-file.\n",
        "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
        "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
        "            # Unpack the tar-ball.\n",
        "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
        "\n",
        "        print(\"Done.\")\n",
        "    else:\n",
        "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
        "\n",
        "\n",
        "def _get_file_path(filename=\"\"):\n",
        "    \"\"\"\n",
        "    Return the full path of a data-file for the data-set.\n",
        "\n",
        "    If filename==\"\" then return the directory of the files.\n",
        "    \"\"\"\n",
        "\n",
        "    return os.path.join(hparams.data_dir, \"cifar-10-batches-py/\", filename)\n",
        "\n",
        "\n",
        "def _unpickle(filename):\n",
        "    \"\"\"\n",
        "    Unpickle the given file and return the data.\n",
        "\n",
        "    Note that the appropriate dir-name is prepended the filename.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create full path for the file.\n",
        "    file_path = _get_file_path(filename)\n",
        "\n",
        "    print(\"Loading data: \" + file_path)\n",
        "\n",
        "    with open(file_path, mode='rb') as file:\n",
        "        # In Python 3.X it is important to set the encoding,\n",
        "        # otherwise an exception is raised here.\n",
        "        data = pickle.load(file,encoding='bytes')\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def _convert_images(raw):\n",
        "    \"\"\"\n",
        "    Convert images from the CIFAR-10 format and\n",
        "    return a 4-dim array with shape: [image_number, height, width, channel]\n",
        "    where the pixels are floats between 0.0 and 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the raw images from the data-files to floating-points.\n",
        "    raw_float = np.array(raw, dtype=float) / 255.0\n",
        "\n",
        "    # Reshape the array to 4-dimensions.\n",
        "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
        "\n",
        "    # Reorder the indices of the array.\n",
        "    images = images.transpose([0, 2, 3, 1])\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def _load_data(filename):\n",
        "    \"\"\"\n",
        "    Load a pickled data-file from the CIFAR-10 data-set\n",
        "    and return the converted images (see above) and the class-number\n",
        "    for each image.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the pickled data-file.\n",
        "    data = _unpickle(filename)\n",
        "\n",
        "    # Get the raw images.\n",
        "    raw_images = data[b'data']\n",
        "\n",
        "    # Get the class-numbers for each image. Convert to numpy-array.\n",
        "    cls = np.array(data[b'labels'])\n",
        "\n",
        "    # Convert the images.\n",
        "    images = _convert_images(raw_images)\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "\n",
        "def load_class_names():\n",
        "    # Load the class-names from the pickled file.\n",
        "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
        "\n",
        "    # Convert from binary strings.\n",
        "    names = [x.decode('utf-8') for x in raw]\n",
        "\n",
        "    return names\n",
        "\n",
        "\n",
        "def load_training_data():\n",
        "    \"\"\"\n",
        "    Load all the training-data for the CIFAR-10 data-set.\n",
        "\n",
        "    The data-set is split into 5 data-files which are merged here.\n",
        "\n",
        "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
        "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
        "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
        "\n",
        "    # Begin-index for the current batch.\n",
        "    begin = 0\n",
        "\n",
        "    # For each data-file.\n",
        "    for i in range(_num_files_train):\n",
        "        # Load the images and class-numbers from the data-file.\n",
        "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
        "\n",
        "        # Number of images in this batch.\n",
        "        num_images = len(images_batch)\n",
        "\n",
        "        # End-index for the current batch.\n",
        "        end = begin + num_images\n",
        "\n",
        "        # Store the images into the array.\n",
        "        images[begin:end, :] = images_batch\n",
        "\n",
        "        # Store the class-numbers into the array.\n",
        "        cls[begin:end] = cls_batch\n",
        "\n",
        "        # The begin-index for the next batch is the current end-index.\n",
        "        begin = end\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "\n",
        "def load_validation_data():\n",
        "\n",
        "    images, cls = _load_data(filename=\"test_batch\")\n",
        "\n",
        "    images = images[5000:, :, :, :]\n",
        "    cls = cls[5000:]\n",
        "\n",
        "    return images, cls\n",
        "\n",
        "def load_testing_data():\n",
        "\n",
        "\n",
        "    images, cls = _load_data(filename=\"test_batch\")\n",
        "\n",
        "    images = images[:5000, :, :, :]\n",
        "    cls = cls[:5000]\n",
        "\n",
        "    return images, cls\n",
        "  \n",
        "maybe_download_and_extract()\n",
        "\n",
        "# training data\n",
        "x_train, y_train = load_training_data()\n",
        "print(\"CIFAR-10 Training Dataset Size: \", x_train.shape)\n",
        "print(\"CIFAR-10 Training Labels Size : \", y_train.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFIzRwBy-QEz",
        "colab_type": "text"
      },
      "source": [
        "Defining Some Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r92Sts41iUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(input, filters, k_size = 3, strides = (1, 1), normalization = True, activation = tf.nn.leaky_relu, training = True, name = None):\n",
        "  conv = tf.keras.layers.Conv2D(filters, k_size, strides, padding = 'same')(input)\n",
        "  if normalization:\n",
        "    conv = tf.keras.layers.BatchNormalization(trainable = False)(conv)\n",
        "  if activation is not None:\n",
        "    out = activation(conv)\n",
        "  else:\n",
        "    out = conv\n",
        "  return out\n",
        "\n",
        "def deconv_layer(input, filters, k_size = 3, strides = (2, 2), normalization = True, activation = tf.nn.relu, training = True, name = None):\n",
        "  deconv = tf.keras.layers.Conv2DTranspose(filters, k_size, strides, padding = 'same')(input)\n",
        "  if normalization:\n",
        "    deconv = tf.keras.layers.BatchNormalization()(deconv)\n",
        "  if activation is not None:\n",
        "    out = activation(deconv)\n",
        "  else:\n",
        "    out = deconv\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXl6sNfx3jL_",
        "colab_type": "text"
      },
      "source": [
        "Defining Generator and Discriminator models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ_JqjEN1BBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator():\n",
        "  inputs = tf.keras.Input(shape = (128))\n",
        "  linear = tf.keras.layers.Dense(4 * 4 * 512, activation = 'relu')(inputs)\n",
        "  linear_reshape = tf.reshape(linear, (-1, 4, 4, 512))\n",
        "  conv_1 = deconv_layer(linear_reshape, filters = 128, k_size = 3, name = 'conv_1')\n",
        "  conv_2 = deconv_layer(conv_1, filters = 64, k_size = 3, name = 'conv_2')\n",
        "  conv_3 = deconv_layer(conv_2, filters = num_channels, k_size = 3, name = 'conv_3')\n",
        "  generator_model = tf.keras.Model(inputs = [inputs], outputs = [conv_3])\n",
        "  return generator_model\n",
        "\n",
        "def discriminator(image_size):\n",
        "  inputs = tf.keras.Input(shape = (image_size, image_size, num_channels))\n",
        "  conv_1 = conv_layer(inputs, filters = 64, k_size = 3, strides = (2, 2), name = 'conv_1')\n",
        "  conv_2 = conv_layer(conv_1, filters = 128, k_size = 3, strides = (2, 2), name = 'conv_2')\n",
        "  conv_3 = conv_layer(conv_2, filters = 256, k_size = 3, strides = (2, 2), name = 'conv_3')\n",
        "  flat = tf.reshape(conv_3, shape = [-1, 4 * 4 * 256])\n",
        "  logits = tf.keras.layers.Dense(1)(flat)\n",
        "  discriminator_model = tf.keras.Model(inputs = [inputs], outputs = [logits])\n",
        "  return discriminator_model\n",
        "\n",
        "generator_model = generator()\n",
        "discriminator_model = discriminator(img_size)\n",
        "print(generator_model.summary())\n",
        "print(discriminator_model.summary())\n",
        "\n",
        "dis_optimizer = tf.keras.optimizers.Adam(learning_rate=hparams.dis_learning_rate)\n",
        "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=hparams.gen_learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SER9CfKq3yKy",
        "colab_type": "text"
      },
      "source": [
        "Defining Generator and Discriminator Loss and Training Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MgQ-agC38-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dis_loss(real_dis, fake_dis):\n",
        "  # real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = real_dis, labels = tf.ones_like(real_dis)))\n",
        "  # fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = fake_dis, labels = tf.zeros_like(fake_dis)))\n",
        "  dis_loss = tf.reduce_mean(fake_dis) - tf.reduce_mean(real_dis)\n",
        "  return dis_loss\n",
        "\n",
        "def gen_loss(fake_dis):\n",
        "  # gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = fake_dis, labels = tf.ones_like(fake_dis)))\n",
        "  gen_loss = - tf.reduce_mean(fake_dis)\n",
        "  return gen_loss\n",
        "\n",
        "@tf.function\n",
        "def dis_train_step(real_image, generator_model, discriminator_model, latent_size, dis_optimizer):\n",
        "  latent_z = tf.random.normal(shape = (tf.shape(real_image)[0], latent_size))\n",
        "  with tf.GradientTape() as dis_tape:\n",
        "    fake_image = generator_model(latent_z)\n",
        "    real_dis = discriminator_model(real_image)\n",
        "    fake_dis = discriminator_model(fake_image)\n",
        "    dis_loss_value = dis_loss(real_dis, fake_dis)\n",
        "\n",
        "  dis_grads = dis_tape.gradient(dis_loss_value, discriminator_model.trainable_variables)\n",
        "  dis_optimizer.apply_gradients(zip(dis_grads, discriminator_model.trainable_variables))\n",
        "\n",
        "  for w in discriminator_model.trainable_variables:\n",
        "    w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
        "\n",
        "  return dis_loss_value, dis_grads\n",
        "\n",
        "@tf.function\n",
        "def gen_train_step(ream_image, generator_model, discriminator_model, latent_size, gen_optimizer):\n",
        "  latent_z = tf.random.normal(shape = (tf.shape(real_image)[0], latent_size))\n",
        "  with tf.GradientTape() as gen_tape:\n",
        "    fake_image = generator_model(latent_z)\n",
        "    fake_dis = discriminator_model(fake_image)\n",
        "    gen_loss_value = gen_loss(fake_dis)\n",
        "\n",
        "  gen_grads = gen_tape.gradient(gen_loss_value, generator_model.trainable_variables)\n",
        "  gen_optimizer.apply_gradients(zip(gen_grads, generator_model.trainable_variables))\n",
        "\n",
        "  return gen_loss_value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0DUfACmMG9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_generated(generated_images, step):\n",
        "  batch_size, channels, height, width = generated_images.shape\n",
        "  length = batch_size // 4\n",
        "  generated_images = (generated_images) * 255.0\n",
        "  generated_images[generated_images > 255.0] = 255.0\n",
        "  generated_images[generated_images < 0.0] = 0.0\n",
        "  for i in range(batch_size):\n",
        "    plt.subplot(4, length, i + 1)\n",
        "    plt.axis('off')\n",
        "    # image = np.transpose(generated_images[i].astype('uint8'), (1, 2, 0))\n",
        "    image = generated_images[i].astype('uint8')\n",
        "    # image = image[:, :, ::-1]\n",
        "    plt.imshow(image)\n",
        "  plt.savefig('generated_images_{}.png'.format(step))\n",
        "  plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9k7xTAP6kXv",
        "colab_type": "text"
      },
      "source": [
        "Training Iterations\n",
        "  fake_image_ = generator_model(latent_z_fixed)\n",
        "  save_generated(fake_image_, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMZWPNBQzw09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/gradient_tape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZXmYaVexzJ43",
        "colab": {}
      },
      "source": [
        "# generator_model.load_weights('./trained_model/ckpt_gen')\n",
        "# discriminator_model.load_weights('./trained_model/ckpt_dis')\n",
        "\n",
        "batch_size = hparams.batch_size\n",
        "epochs = hparams.n_epochs\n",
        "latent_size = hparams.latent_size\n",
        "\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "tf_dataset = tf_dataset.shuffle(5000).batch(batch_size)\n",
        "\n",
        "latent_z_fixed = tf.random.normal(shape = (batch_size, latent_size))\n",
        "\n",
        "dis_log_dir = 'logs/gradient_tape/' + '/dis'\n",
        "gen_log_dir = 'logs/gradient_tape/' + '/gen'\n",
        "dis_summary_writer = tf.summary.create_file_writer(dis_log_dir)\n",
        "gen_summary_writer = tf.summary.create_file_writer(gen_log_dir)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  step = 0\n",
        "  for real_image in tf_dataset:\n",
        "    step += 1\n",
        "    \n",
        "    dis_loss_, dis_grads_ = dis_train_step(real_image, generator_model, discriminator_model, latent_size, dis_optimizer)\n",
        "    if step % hparams.n_critic == 0:\n",
        "      gen_loss_ = gen_train_step(real_image, generator_model, discriminator_model, latent_size, gen_optimizer)\n",
        "    # if step % 500 == 0:\n",
        "    #   print(\"Step: {}  Discriminator loss: {}  Generator loss {}\".format(step, dis_loss_, gen_loss_))\n",
        "  \n",
        "  print(\"Epoch: {}  Discriminator loss: {}  Generator loss {}\".format(epoch, dis_loss_, gen_loss_))\n",
        "  with dis_summary_writer.as_default():\n",
        "    tf.summary.scalar('dis_loss', dis_loss_, step = epoch)\n",
        "  with gen_summary_writer.as_default():\n",
        "    tf.summary.scalar('gen_loss', gen_loss_, step = epoch)\n",
        "\n",
        "  fake_image_ = generator_model(latent_z_fixed)\n",
        "  save_generated(fake_image_.numpy(), epoch)\n",
        "  \n",
        "  generator_model.save_weights('./trained_model/ckpt_gen')\n",
        "  discriminator_model.save_weights('./trained_model/ckpt_dis')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj9x1qefsxM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='generated_images_{}.png'.format(epochs - 1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze7yXUeKOJ_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf *.png"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}